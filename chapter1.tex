\chapter{Introduction}
\cite{Atkins2003} identifies a revolution in integrated, computationally based scientific research which leverages High Performance Computing (HPC) capabilities in spatially and computationally distributed environments, a Cyberinfrastructure (CI) environment.  This cyber environment exists at the convergence of high performance computing infrastructure, scalable algorithms, large scale high availability data, and distributed collaboration between domain experts.  A subset of CI, Geographic Cyberinfrastructure (GCI) supports the tenants of CI while acknowledging that the spatially enabled data volumes and the ability to leverage spatial information in integrated analytical environments are rapidly increasing \citep{Yang2010}.  Not only have increases in spatial data collection and usage increased, but so have the complexity of the computational models used to derive analytical results \citep{Anselin2012, Yang2008, Yang2009, Yang2010}.  The development and refactoring of scalable spatial analysis algorithms, in the vector domain, has not kept pace with the computational costs associated with supporting Big Data and / or Big Process analysis.  Without data reduction or model simplification steps the application of methods to existing data is intractable.  The integration of spatial analysis methods into the GCI requires the development of scalable analytics.  This in turn requires that the development of scalable spatial analysis methods be accessible to users.

\cite{Atkins2003} suggests that the techniques and technology which drive high performance, parallel computing, outpace the functionality and accessibility required by end users to make use of cutting edge techniques to drive computationally based research.  For example, the application of automatic, compiler level vectorization and parallelization methods has been largely superseded by the need to embed Message Passing Interface directly into code \citep{Atkins2003}.  This significantly raises the bar of entry for users wishing to leverage distributed computation in an HPC environment. More recently, and within the context of Geospatial Cyber Infrastructure, \cite{Wang2009} identifies parallel geospatial processing as an essential research area and offers a theoretical model designed to drive the decomposition of set of mathematical operations to support parallel computation.  Therefore, both the development of parallel spatial algorithms and the development of a methodology to support development of said algorithms by end users, a taxonomy,  is required.

At an atomic level, spatial analytical algorithms are a series mathematical operations.  These operations are traditionally performed in serial, on a single processing core, requiring some amount of time.  As an algorithm increases in complexity or is applied to a large set of data, the number of computations, $n$ increases, resulting in increased compute times.  Parallel computation is the act of distributing $n$ computations over $c$ processing cores, with a maximum theoretical speedup of $\frac{n}{c}$\citep{Grama:2003aa}.  Input and output, excess computation, communication costs, and the quantity of $n$ that must be computed in serial all reduce the theoretical maximum.  The costs incurred which reduce the total speedup are a function of the decomposition strategy, inter-core communication patterns, and hardware.  Therefore, a successful parallelization requires the, potentially iterative, development of an algorithm which ideally balances decomposition and communication on a given hardware platform.

Considerable research effort has been applied to the theoretical benefits attainable through parallel spatial algorithm implementation \citep{Armstrong1992, Clematis:2003aa, Wang2003, Yang2008, Yang2011}, the application of distributed spatial algorithm computation on dedicated hardware, i.e. supercomputers, clusters, clouds, and GPUs \citep{Armstrong1994, Armstrong1995, Armstrong1996, Puri:2014aa, Shook2013,  Xie:2010aa, Xia:2011aa, Widener:2012aa, Yang2009}, and the development of parallel GIS operation implementations within the computational geometry domain, e.g., overlay and intersection \citep{blelloch:1988, Healey1998, Puri:2014aa}.  

Previous efforts have left two knowledge gaps in this specific GIScience research domain.  First, multi-core Shared Memory Processing (SMP) computers, e.g. desktop and laptop computers, remain a primary analytical platform \citep{Goodchild1993, Unwin1996}.  Most existing research focuses on high performance computing hardware and frequently results in tightly coupled, non-portable, implementation specifics.  Second, the theoretical benefits attainable through parallelization have not been realized across the analytic stack as previous research used a depth first approach where common implementations are tested across varied hardware environments.
This is in contrast to the breadth first search utilized here that seeks to target the wider spatial analysis stack across generalized hardware representations.
The original contribution of this dissertation is the development of parallel algorithm implementations in the Symmetric Multi-Processor (SMP) environment with portability to HPC architectures and the creation of a taxonomy of proven implementation techniques that spans the spatial analysis stack.

\subsection*{Organization}
Chapter 2 of this dissertation proposes taxonomy of parallel spatial algorithm implementations.  The development of the taxonomy is cited at the intersection of parallel computing research from the computer science domain and spatial analysis methods from the Geographic Information Science (GIScience) domain.  \cite{Asanovic:2006aa} offer a high level classification of commonly encounter mathematical models, dwarfs, within a parallel computing context.  In conjunction with taxonomic classifications of metaheuristic methods, drawn from the spatial optimization and operations research domains \citep{Trienekens1992, Crainic1997, James:2009aa}, I extended the classification of dwarfs to acknowledge that spatial data provides additional, leveragable information at the potential cost of additional algorithm complexity.  The population of the taxonomy is driven through the use of existing parallelization efforts from the GIScience literature as well as the implementation of representative spatial algorithms.  Four existing dwarfs (described in Chapter 2) are leveraged to classify a subset of the spatial analysis stack.  These are: (1) Map Reduce, (2) Dense Linear Algebra and (3) Sparse Linear Algebra.  Additionally, I propose three new dwarfs which leverage the notation that the spatial information contained within the data is inherently special and provides opportunities for improved parallel performance.  These are: (1) Topological, (2) Geometric, and (3) Exploratory.  Through this taxonomy, a set of best practices is articulated to support parallelization efforts, by users, with significantly reduced overhead costs.

Chapter 3 begins a series of four chapters focusing on the implementation of parallel algorithms from across the spatial analysis stack to support and document classifications provided in Chapter 1. I explore the classification of the Fisher-Jenks optimal choropleth map classification algorithm \citep{Hartigan1975,Rey2013} as a dense linear algebra atomic dwarf and sparse Cholesky decomposition \citep{Santos:2003aa} as a sparse linear algebra atomic dwarf in SMP and HPC environments.  These algorithms provide two commonly encounter data representations in two divergent compute environments.  In developing SMP implementations I explore the use of a lockless shared memory space to significantly reduce communication costs, showing that this methods provides significant speed improvement, but lacks scalability to large problem sizes.  In the HPC environment, I propose excess computation models that leverage fine grained point-to-point communication model and collective communication paradigms.  Exploring both communication models provides insight into the suitability of each method as a function of data density, memory availability, and communication (network) latency.

In Chapter 4...

Chapter 5 focuses on the implementation of geometric compute dwarfs 

In Chapter 6

Chapter 7 concludes this dissertation by synthesizing the previous four chapters in light of the taxonomy developed in Chapter 2.  Leveraging the proposed taxonomy and in-depth implementation artifacts, parallelization of a wider breadth of the spatial analysis stack is made viable in both SMP and HPC compute environments.  Extensions to this work can focus on the identification of spatial methods which do not conform well to the existing dwarfs, the application of parallelization methods to spatio-temporal methods, and the development of automated parallelization and vectorization capabilities for spatial algorithms.